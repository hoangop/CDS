import os
import time
import json
import re
import base64
import psycopg2
from duckduckgo_search import DDGS
from playwright.sync_api import sync_playwright
import google.generativeai as genai
from PIL import Image

# --- C·∫§U H√åNH ---
# API Key Gemini (L·∫•y t·ª´ bi·∫øn m√¥i tr∆∞·ªùng ho·∫∑c hardcode t·∫°m th·ªùi ƒë·ªÉ test)
API_KEY = os.getenv("GOOGLE_API_KEY", "AIzaSyAFm53agSZhTicTqLYzuiQG7ZwPmpvZpf8")
genai.configure(api_key=API_KEY)

DB_CONFIG = {
    "dbname": "cds_db",
    "user": "postgres",
    "password": "postgres",
    "host": "localhost",
    "port": "5432"
}

# --- DATABASE FUNCTIONS ---

def setup_database():
    """Th√™m c·ªôt Rank v√†o b·∫£ng Institution_Master n·∫øu ch∆∞a c√≥."""
    conn = psycopg2.connect(**DB_CONFIG)
    cur = conn.cursor()
    try:
        print("ƒêang c·∫≠p nh·∫≠t Schema Database...")
        cur.execute("""
            ALTER TABLE Institution_Master 
            ADD COLUMN IF NOT EXISTS Rank_2025 INTEGER,
            ADD COLUMN IF NOT EXISTS Rank_Type VARCHAR(255);
        """)
        conn.commit()
        print("‚úì ƒê√£ c·∫≠p nh·∫≠t Schema.")
    except Exception as e:
        print(f"‚ùå L·ªói Schema: {e}")
        conn.rollback()
    finally:
        conn.close()

def get_schools_to_update(limit=10):
    """L·∫•y danh s√°ch c√°c tr∆∞·ªùng ch∆∞a c√≥ Rank."""
    conn = psycopg2.connect(**DB_CONFIG)
    cur = conn.cursor()
    # ∆Øu ti√™n c√°c tr∆∞·ªùng ƒë√£ c√≥ d·ªØ li·ªáu tuy·ªÉn sinh nh∆∞ng ch∆∞a c√≥ rank
    query = """
        SELECT im.Institution_ID, im.Name 
        FROM Institution_Master im
        JOIN Admission_C ac ON im.Institution_ID = ac.Institution_ID
        WHERE im.Rank_2025 IS NULL 
        AND ac.Total_Applicants > 0
        ORDER BY im.Name ASC
        LIMIT %s;
    """
    cur.execute(query, (limit,))
    rows = cur.fetchall()
    conn.close()
    return rows

def update_school_rank(inst_id, rank, rank_type):
    """C·∫≠p nh·∫≠t rank v√†o DB."""
    conn = psycopg2.connect(**DB_CONFIG)
    cur = conn.cursor()
    try:
        cur.execute("""
            UPDATE Institution_Master 
            SET Rank_2025 = %s, Rank_Type = %s
            WHERE Institution_ID = %s;
        """, (rank, rank_type, inst_id))
        conn.commit()
        print(f"‚úì ƒê√£ l∆∞u DB: {inst_id} -> #{rank} {rank_type}")
    except Exception as e:
        print(f"‚ùå L·ªói Update DB: {e}")
        conn.rollback()
    finally:
        conn.close()

# --- SEARCH & BROWSER FUNCTIONS ---

import requests
from bs4 import BeautifulSoup

def find_usnews_url_and_capture(school_name, output_path="temp_screenshot.png"):
    """D√πng Playwright ƒë·ªÉ Search Google V√Ä Ch·ª•p ·∫£nh lu√¥n (All-in-one)."""
    print(f"üîç Searching & Capturing: {school_name}...")
    
    try:
        with sync_playwright() as p:
            # Gi·∫£ l·∫≠p browser m·∫°nh h∆°n n·ªØa
            browser = p.chromium.launch(headless=True, args=[
                '--disable-blink-features=AutomationControlled',
                '--no-sandbox',
                '--disable-setuid-sandbox',
                '--disable-infobars',
                '--window-position=0,0',
                '--ignore-certificate-errors',
                '--ignore-ssl-errors',
                '--disable-http2', # QUAN TR·ªåNG: T·∫Øt HTTP2 ƒë·ªÉ tr√°nh l·ªói protocol error
                '--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36'
            ])
            
            context = browser.new_context(
                viewport={"width": 1920, "height": 1080},
                user_agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
                locale="en-US",
                timezone_id="America/New_York",
                device_scale_factor=1,
                has_touch=False,
                is_mobile=False,
                java_script_enabled=True,
            )
            
            # Th√™m headers gi·∫£ l·∫≠p
            context.set_extra_http_headers({
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
                "Accept-Language": "en-US,en;q=0.9",
                "Cache-Control": "no-cache",
                "Pragma": "no-cache",
                "Sec-Ch-Ua": '"Chromium";v="122", "Not(A:Brand";v="24", "Google Chrome";v="122"',
                "Sec-Ch-Ua-Mobile": "?0",
                "Sec-Ch-Ua-Platform": '"macOS"',
                "Sec-Fetch-Dest": "document",
                "Sec-Fetch-Mode": "navigate",
                "Sec-Fetch-Site": "none",
                "Sec-Fetch-User": "?1",
                "Upgrade-Insecure-Requests": "1"
            })

            # Script che d·∫•u v·∫øt
            context.add_init_script("""
                Object.defineProperty(navigator, 'webdriver', { get: () => undefined });
                Object.defineProperty(navigator, 'languages', { get: () => ['en-US', 'en'] });
                Object.defineProperty(navigator, 'plugins', { get: () => [1, 2, 3, 4, 5] });
            """)
            
            page = context.new_page()
            
            # 1. V√†o Google
            try:
                page.goto("https://www.google.com", timeout=30000)
            except Exception:
                print("   ‚ö†Ô∏è L·ªói truy c·∫≠p Google, th·ª≠ Bing...")
                page.goto("https://www.bing.com", timeout=30000)

            time.sleep(2)
            
            # 2. Search
            query = f"{school_name} us news ranking site:usnews.com/best-colleges"
            
            # Check xem ƒëang ·ªü Google hay Bing ƒë·ªÉ fill ƒë√∫ng selector
            if "google" in page.url:
                page.fill("textarea[name='q']", query)
                page.press("textarea[name='q']", "Enter")
                page.wait_for_selector("#search", timeout=10000)
            else:
                page.fill("input[name='q']", query)
                page.press("input[name='q']", "Enter")
                time.sleep(3)
            
            time.sleep(2)
            
            # 3. L·∫•y link ƒë·∫ßu ti√™n
            target_url = None
            
            # Logic l·∫•y link cho c·∫£ Google v√† Bing
            links = page.locator("a[href*='usnews.com/best-colleges/']")
            count = links.count()
            
            for i in range(count):
                href = links.nth(i).get_attribute("href")
                if href and "rankings" not in href and "search" not in href and "google" not in href:
                    target_url = href
                    print(f"   -> Found URL: {target_url}")
                    break
            
            if not target_url:
                print("   ‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y link ph√π h·ª£p.")
                browser.close()
                return False

            # 4. V√†o trang ƒë√≠ch
            print(f"   üì∏ Accessing: {target_url}")
            
            # Th·ª≠ load trang v·ªõi chi·∫øn thu·∫≠t retry
            try:
                response = page.goto(target_url, timeout=60000, wait_until="domcontentloaded")
                if response and response.status == 403:
                    print("   ‚ùå B·ªã ch·∫∑n 403 Forbidden.")
                    browser.close()
                    return False
            except Exception as e:
                print(f"   ‚ùå L·ªói load trang: {e}")
                browser.close()
                return False
            
            # ƒê·ª£i load v√† bypass popup n·∫øu c√≥
            time.sleep(5)
            
            # T·∫Øt popup qu·∫£ng c√°o n·∫øu c√≥ (th·ª≠)
            try:
                page.evaluate("document.querySelectorAll('div[class*=\"popup\"], div[class*=\"modal\"]').forEach(el => el.remove());")
            except:
                pass

            # Cu·ªôn trang ƒë·ªÉ trigger lazy load
            page.mouse.wheel(0, 500)
            time.sleep(3)
            
            # Ch·ª•p ·∫£nh
            page.screenshot(path=output_path, clip={"x": 0, "y": 0, "width": 1280, "height": 1200})
            print("   ‚úì ƒê√£ ch·ª•p ·∫£nh.")
            
            browser.close()
            return True
            
    except Exception as e:
        print(f"‚ùå L·ªói Browser: {e}")
        return False

# --- LLM EXTRACT FUNCTION ---

def extract_rank_from_image(image_path):
    """G·ª≠i ·∫£nh cho Gemini ƒë·ªÉ l·∫•y Rank v√† Type."""
    print("   ü§ñ Asking Gemini...")
    
    try:
        model = genai.GenerativeModel('gemini-2.0-flash-exp')
        
        prompt = """
        Look at this screenshot of a US News university profile page.
        Your task is to find the University Ranking information.
        
        1. Look for a large number preceded by a '#' symbol (e.g., #17, #1, #105). This is the rank.
        2. Look for the text immediately following or near that number (e.g., "National Universities", "Liberal Arts Colleges", "Regional Universities West"). This is the rank type.
        
        Return the result as a purely valid JSON object. Do not include markdown formatting.
        Format:
        {
            "rank": <integer or null>,
            "type": "<string or null>"
        }
        
        If you cannot find the rank, return null.
        """
        
        img = Image.open(image_path)
        response = model.generate_content([prompt, img])
        
        # Clean response text (remove markdown ```json ... ```)
        text = response.text.strip()
        if text.startswith("```json"):
            text = text[7:]
        if text.endswith("```"):
            text = text[:-3]
            
        data = json.loads(text)
        print(f"   -> Result: {data}")
        return data
    except Exception as e:
        print(f"   ‚ùå L·ªói LLM: {e}")
        return None

# --- MAIN FLOW ---

def main():
    setup_database()
    
    # L·∫•y danh s√°ch tr∆∞·ªùng c·∫ßn update (tƒÉng limit l√™n 50)
    schools = get_schools_to_update(limit=200)
    
    if not schools:
        print("Kh√¥ng c√≥ tr∆∞·ªùng n√†o c·∫ßn c·∫≠p nh·∫≠t.")
        return

    print(f"ƒê√£ t√¨m th·∫•y {len(schools)} tr∆∞·ªùng c·∫ßn c·∫≠p nh·∫≠t rank.\n")

    for inst_id, name in schools:
        print("-" * 50)
        print(f"ƒêang x·ª≠ l√Ω: {name}")
        
        img_path = f"temp_rank_{inst_id}.png"
        
        # G·ªçi h√†m All-in-one: Search + Capture
        success = find_usnews_url_and_capture(name, img_path)
        
        if success:
            # Tr√≠ch xu·∫•t b·∫±ng AI
            result = extract_rank_from_image(img_path)
            
            # C·∫≠p nh·∫≠t DB
            if result and result.get('rank'):
                update_school_rank(inst_id, result['rank'], result['type'])
            else:
                print("   ‚ö†Ô∏è Kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c rank t·ª´ ·∫£nh.")
                
            # D·ªçn d·∫πp file ·∫£nh
            if os.path.exists(img_path):
                os.remove(img_path)
        else:
            print("   ‚ö†Ô∏è Th·∫•t b·∫°i khi t√¨m ki·∫øm/ch·ª•p ·∫£nh.")
            
        # Ngh·ªâ nh·∫π
        time.sleep(2)

    print("\n================ DONE ================")

if __name__ == "__main__":
    main()

